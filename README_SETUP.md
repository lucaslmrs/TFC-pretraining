# TFC - Time-Frequency Contrastive Learning

Guia completo para configuraÃ§Ã£o e execuÃ§Ã£o do TFC (Time-Frequency Contrastive Learning) para prÃ©-treinamento auto-supervisionado de sÃ©ries temporais.

## ğŸ“‹ Ãndice

1. [Requisitos do Sistema](#requisitos-do-sistema)
2. [InstalaÃ§Ã£o do Ambiente](#instalaÃ§Ã£o-do-ambiente)
3. [Download dos Datasets](#download-dos-datasets)
4. [Estrutura do Projeto](#estrutura-do-projeto)
5. [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
6. [ExecuÃ§Ã£o do Treinamento](#execuÃ§Ã£o-do-treinamento)
7. [CenÃ¡rios de Transfer Learning](#cenÃ¡rios-de-transfer-learning)
8. [SoluÃ§Ã£o de Problemas](#soluÃ§Ã£o-de-problemas)

---

## ğŸ–¥ï¸ Requisitos do Sistema

### Hardware
| Componente | MÃ­nimo | Recomendado |
|------------|--------|-------------|
| RAM | 8 GB | 16 GB |
| GPU VRAM | 4 GB (GTX 1650) | 8 GB+ (RTX 3070+) |
| Disco | 10 GB | 20 GB |

### Software
- **Sistema Operacional**: Linux (Ubuntu 20.04+) ou WSL2 no Windows
- **Python**: 3.9 (gerenciado via Conda)
- **CUDA**: 12.1+ (para treinamento com GPU)
- **Driver NVIDIA**: 530+ (para GPU)

### Verificar GPU (WSL2)
```bash
# No WSL, verificar se a GPU estÃ¡ acessÃ­vel
ls /usr/lib/wsl/lib/
# Deve mostrar: libcuda.so, libnvidia-ml.so.1, nvidia-smi, etc.

# Testar nvidia-smi
/usr/lib/wsl/lib/nvidia-smi
```

---

## ğŸ”§ InstalaÃ§Ã£o do Ambiente

### Passo 1: Instalar Miniconda

```bash
# Baixar Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh

# Instalar
bash miniconda.sh -b -p $HOME/miniconda3

# Inicializar conda no shell
~/miniconda3/bin/conda init bash

# Reiniciar o terminal ou executar:
source ~/.bashrc
```

### Passo 2: Criar Ambiente Conda

```bash
cd ~/projetos/TFC-pretraining

# Criar ambiente a partir do arquivo simplificado
conda env create -f requirements_simplified.yml

# Ativar ambiente
conda activate tfc
```

### Passo 3: Instalar PyTorch com CUDA (GPU)

```bash
conda activate tfc

# Remover PyTorch CPU e instalar com CUDA
pip uninstall -y torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Passo 4: Verificar InstalaÃ§Ã£o

```bash
conda activate tfc

# Verificar versÃµes
python -c "
import torch
print(f'Python: {torch.__version__}')
print(f'PyTorch: {torch.__version__}')
print(f'CUDA disponÃ­vel: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
"
```

**SaÃ­da esperada:**
```
PyTorch: 2.5.1+cu121
CUDA disponÃ­vel: True
GPU: NVIDIA GeForce GTX 1650
```

---

## ğŸ“¥ Download dos Datasets

### OpÃ§Ã£o 1: Script AutomÃ¡tico

```bash
cd ~/projetos/TFC-pretraining
bash download_datasets.sh
```

### OpÃ§Ã£o 2: Download Manual (se o script falhar)

```bash
cd ~/projetos/TFC-pretraining

# Baixar cada dataset
curl -L -A "Mozilla/5.0" -o SleepEEG.zip "https://figshare.com/ndownloader/articles/19930178/versions/1"
curl -L -A "Mozilla/5.0" -o Epilepsy.zip "https://figshare.com/ndownloader/articles/19930199/versions/2"
curl -L -A "Mozilla/5.0" -o FD-A.zip "https://figshare.com/ndownloader/articles/19930205/versions/1"
curl -L -A "Mozilla/5.0" -o FD-B.zip "https://figshare.com/ndownloader/articles/19930226/versions/1"
curl -L -A "Mozilla/5.0" -o HAR.zip "https://figshare.com/ndownloader/articles/19930244/versions/1"
curl -L -A "Mozilla/5.0" -o Gesture.zip "https://figshare.com/ndownloader/articles/19930247/versions/1"
curl -L -A "Mozilla/5.0" -o ECG.zip "https://figshare.com/ndownloader/articles/19930253/versions/1"
curl -L -A "Mozilla/5.0" -o EMG.zip "https://figshare.com/ndownloader/articles/19930250/versions/1"

# Extrair
unzip SleepEEG.zip -d datasets/SleepEEG/
unzip Epilepsy.zip -d datasets/Epilepsy/
unzip FD-A.zip -d datasets/FD-A/
unzip FD-B.zip -d datasets/FD-B/
unzip HAR.zip -d datasets/HAR/
unzip Gesture.zip -d datasets/Gesture/
unzip ECG.zip -d datasets/ECG/
unzip EMG.zip -d datasets/EMG/

# Criar links simbÃ³licos (necessÃ¡rio para FD_A e FD_B)
cd datasets
ln -sf FD-A FD_A
ln -sf FD-B FD_B

# Limpar arquivos zip
cd ..
rm -f *.zip
```

### Verificar Datasets

```bash
ls -lh datasets/*/train.pt
```

**SaÃ­da esperada:**
```
88K     datasets/Epilepsy/train.pt
1.4M    datasets/EMG/train.pt
1.6M    datasets/Gesture/train.pt
2.4M    datasets/FD-B/train.pt
14M     datasets/HAR/train.pt
286M    datasets/SleepEEG/train.pt
501M    datasets/ECG/train.pt
553M    datasets/FD-A/train.pt
```

---

## ğŸ“ Estrutura do Projeto

```
TFC-pretraining/
â”œâ”€â”€ datasets/                      # Datasets
â”‚   â”œâ”€â”€ SleepEEG/                  # PrÃ©-treino (EEG)
â”‚   â”œâ”€â”€ Epilepsy/                  # Fine-tuning (EEG)
â”‚   â”œâ”€â”€ HAR/                       # PrÃ©-treino (Atividade)
â”‚   â”œâ”€â”€ Gesture/                   # Fine-tuning (Atividade)
â”‚   â”œâ”€â”€ FD-A/ (FD_A)               # PrÃ©-treino (Falhas)
â”‚   â”œâ”€â”€ FD-B/ (FD_B)               # Fine-tuning (Falhas)
â”‚   â”œâ”€â”€ ECG/                       # PrÃ©-treino (CardÃ­aco)
â”‚   â””â”€â”€ EMG/                       # Fine-tuning (Muscular)
â”‚
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ TFC/                       # CÃ³digo principal
â”‚   â”‚   â”œâ”€â”€ main.py                # Ponto de entrada
â”‚   â”‚   â”œâ”€â”€ model.py               # Arquitetura TFC
â”‚   â”‚   â”œâ”€â”€ trainer.py             # Loop de treinamento
â”‚   â”‚   â”œâ”€â”€ dataloader.py          # Carregamento de dados
â”‚   â”‚   â”œâ”€â”€ augmentations.py       # AugmentaÃ§Ãµes tempo/frequÃªncia
â”‚   â”‚   â”œâ”€â”€ loss.py                # FunÃ§Ã£o de perda NTXent
â”‚   â”‚   â””â”€â”€ utils.py               # UtilitÃ¡rios
â”‚   â”‚
â”‚   â”œâ”€â”€ config_files/              # ConfiguraÃ§Ãµes por dataset
â”‚   â”‚   â”œâ”€â”€ SleepEEG_Configs.py
â”‚   â”‚   â”œâ”€â”€ HAR_Configs.py
â”‚   â”‚   â”œâ”€â”€ FD_A_Configs.py
â”‚   â”‚   â””â”€â”€ ECG_Configs.py
â”‚   â”‚
â”‚   â””â”€â”€ experiments_logs/          # Logs e modelos salvos
â”‚
â”œâ”€â”€ requirements_simplified.yml    # DependÃªncias Conda
â”œâ”€â”€ download_datasets.sh           # Script de download
â””â”€â”€ README_SETUP.md                # Este arquivo
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivos de ConfiguraÃ§Ã£o

Cada dataset tem seu arquivo em `code/config_files/`. Principais parÃ¢metros:

```python
class Config(object):
    def __init__(self):
        # Arquitetura
        self.input_channels = 1          # Canais de entrada
        self.final_out_channels = 128    # DimensÃ£o do embedding
        
        # Treinamento
        self.num_epoch = 40              # Ã‰pocas
        self.batch_size = 128            # Batch size (ajustar para GPU)
        self.lr = 3e-4                   # Learning rate
        
        # Dados
        self.TSlength_aligned = 178      # Comprimento da sÃ©rie temporal
        self.num_classes = 5             # Classes do dataset fonte
        self.num_classes_target = 2      # Classes do dataset alvo
```

### Ajustar para GPU com Pouca VRAM (4GB)

Se estiver usando GTX 1650 ou similar, reduza o batch_size:

```python
# Em config_files/FD_A_Configs.py
self.batch_size = 8           # Reduzir de 64 para 8
self.target_batch_size = 8    # Reduzir de 60 para 8
```

### Modo Debug vs Completo

No arquivo `main.py`, linha 92:

```python
# Para debug (rÃ¡pido, poucos dados)
subset = True

# Para treinamento completo
subset = False
```

---

## ğŸš€ ExecuÃ§Ã£o do Treinamento

### Comandos BÃ¡sicos

```bash
# Ativar ambiente
conda activate tfc

# Ir para pasta do cÃ³digo
cd ~/projetos/TFC-pretraining/code/TFC
```

### Fase 1: PrÃ©-treinamento

```bash
# Sintaxe
python main.py --training_mode pre_train \
               --pretrain_dataset <DATASET_FONTE> \
               --target_dataset <DATASET_ALVO> \
               --device cuda

# Exemplo: SleepEEG â†’ Epilepsy
python main.py --training_mode pre_train \
               --pretrain_dataset SleepEEG \
               --target_dataset Epilepsy \
               --device cuda

# Exemplo: HAR â†’ Gesture (menor, bom para GPUs com 4GB)
python main.py --training_mode pre_train \
               --pretrain_dataset HAR \
               --target_dataset Gesture \
               --device cuda
```

### Fase 2: Fine-tuning e Teste

```bash
# Sintaxe
python main.py --training_mode fine_tune_test \
               --pretrain_dataset <DATASET_FONTE> \
               --target_dataset <DATASET_ALVO> \
               --device cuda

# Exemplo
python main.py --training_mode fine_tune_test \
               --pretrain_dataset SleepEEG \
               --target_dataset Epilepsy \
               --device cuda
```

### ParÃ¢metros da Linha de Comando

| ParÃ¢metro | Valores | DescriÃ§Ã£o |
|-----------|---------|-----------|
| `--training_mode` | `pre_train`, `fine_tune_test` | Modo de treinamento |
| `--pretrain_dataset` | `SleepEEG`, `HAR`, `FD_A`, `ECG` | Dataset fonte |
| `--target_dataset` | `Epilepsy`, `Gesture`, `FD_B`, `EMG` | Dataset alvo |
| `--device` | `cuda`, `cpu` | Dispositivo |
| `--seed` | `42` (default) | Seed para reprodutibilidade |
| `--logs_save_dir` | `../experiments_logs` | DiretÃ³rio de logs |

---

## ğŸ”„ CenÃ¡rios de Transfer Learning

O TFC suporta 4 cenÃ¡rios de transferÃªncia entre domÃ­nios:

| CenÃ¡rio | PrÃ©-treino | Fine-tuning | DomÃ­nio | Tamanho | GPU 4GB |
|---------|------------|-------------|---------|---------|---------|
| 1 | SleepEEG | Epilepsy | EEG NeurolÃ³gico | 286M â†’ 88K | âœ… |
| 2 | HAR | Gesture | Reconhecimento de Atividade | 14M â†’ 1.6M | âœ… |
| 3 | FD_A | FD_B | DetecÃ§Ã£o de Falhas | 553M â†’ 2.4M | âŒ |
| 4 | ECG | EMG | Monitoramento FÃ­sico | 501M â†’ 1.4M | âš ï¸ |

### RecomendaÃ§Ãµes por GPU

- **GTX 1650 (4GB)**: Use cenÃ¡rios 1 ou 2
- **RTX 3060 (8GB)**: Todos os cenÃ¡rios funcionam
- **RTX 3080+ (10GB+)**: Use batch_size original

---

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Erro: `ModuleNotFoundError: No module named 'numpy'`

**Causa**: Ambiente conda nÃ£o estÃ¡ ativado.

**SoluÃ§Ã£o**:
```bash
conda activate tfc
```

### Erro: `CUDA out of memory`

**Causa**: GPU nÃ£o tem VRAM suficiente.

**SoluÃ§Ãµes**:
1. Reduzir `batch_size` no arquivo de configuraÃ§Ã£o
2. Usar dataset menor (HAR â†’ Gesture)
3. Usar CPU: `--device cpu`

```python
# Em config_files/<Dataset>_Configs.py
self.batch_size = 8           # Reduzir
self.target_batch_size = 8    # Reduzir
```

### Erro: `FileNotFoundError: No such file or directory: '../../datasets/FD_A/train.pt'`

**Causa**: Falta link simbÃ³lico para FD_A/FD_B.

**SoluÃ§Ã£o**:
```bash
cd ~/projetos/TFC-pretraining/datasets
ln -sf FD-A FD_A
ln -sf FD-B FD_B
```

### Erro: `RuntimeError: Found no NVIDIA driver`

**Causa**: Driver NVIDIA nÃ£o instalado ou WSL sem suporte a GPU.

**SoluÃ§Ã£o (WSL2)**:
1. Instale driver NVIDIA no Windows: https://www.nvidia.com/Download/index.aspx
2. Reinicie o computador
3. Verifique: `ls /usr/lib/wsl/lib/` deve mostrar `libcuda.so`

### Erro: `TypeError: expected Tensor as element 0, but got numpy.ndarray`

**Causa**: Dataset tem formato numpy ao invÃ©s de tensor.

**SoluÃ§Ã£o**: JÃ¡ corrigido no `dataloader.py`. Se persistir, verifique se estÃ¡ usando a versÃ£o atualizada do cÃ³digo.

### Erro: `ValueError: Expected more than 1 value per channel when training`

**Causa**: Batch size muito pequeno para BatchNorm.

**SoluÃ§Ã£o**: Aumente `batch_size` para no mÃ­nimo 2 (recomendado: 8+).

---

## ğŸ“Š Resultados Esperados

ApÃ³s o fine-tuning, vocÃª verÃ¡ mÃ©tricas como:

```
MLP Testing: Acc=85.00 | Precision = 84.50 | Recall = 83.20 | F1 = 83.80 | AUROC= 92.10 | AUPRC=88.50
KNN Testing: Acc=82.00 | Precision = 81.20 | Recall = 80.50 | F1 = 80.80 | AUROC= 90.30 | AUPRC=86.20
```

### Modelos Salvos

Os modelos sÃ£o salvos em:
```
code/experiments_logs/<Pretrain>_2_<Target>/run1/
â”œâ”€â”€ pre_train_seed_42_2layertransformer/
â”‚   â””â”€â”€ saved_models/
â”‚       â””â”€â”€ ckp_last.pt          # Checkpoint do prÃ©-treino
â””â”€â”€ fine_tune_test_seed_42_2layertransformer/
    â””â”€â”€ saved_models/
        â””â”€â”€ ckp_last.pt          # Checkpoint do fine-tuning
```

---

## ğŸ“š ReferÃªncias

- **Paper**: [Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency](https://arxiv.org/abs/2206.08496)
- **RepositÃ³rio Original**: https://github.com/mims-harvard/TFC-pretraining

---

## âœ… Checklist de InstalaÃ§Ã£o

- [ ] Miniconda instalado
- [ ] Ambiente `tfc` criado
- [ ] PyTorch com CUDA instalado
- [ ] GPU detectada (`torch.cuda.is_available() == True`)
- [ ] Datasets baixados e extraÃ­dos
- [ ] Links simbÃ³licos FD_A/FD_B criados
- [ ] PrÃ©-treinamento executado com sucesso
- [ ] Fine-tuning executado com sucesso
